{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"content-type\"><style type=\"text/css\">ol</style></head><body class=\"c5\"><p class=\"c0 c4\"><span class=\"c3\"></span></p><p class=\"c2 title\" id=\"h.rrbabt268i6e\"><h1>CaImAn&rsquo;s Demo pipeline</h1></p><p class=\"c0\"><span class=\"c3\">This notebook will help to demonstrate the process of CaImAn and how it uses different functions to denoise, deconvolve and demix neurons from a Calcium Imaging Video. </span></p>\n",
    "<p><img src=\"docs/img/quickintro.png\" /></p>\n",
    "<p class=\"c0\"><span class=\"c3\">More information can be found in CaImAn&rsquo;s documentation. </span></p>\n",
    "</html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"c282afc9-8472-4aab-a8f4-29bc6a69d6bd\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import zip\n",
    "from builtins import str\n",
    "from builtins import map\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')    \n",
    "except:\n",
    "    print('Not IPYTHON')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic(u'matplotlib qt')   \n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import inspect_correlation_pnr\n",
    "from caiman.components_evaluation import estimate_components_quality_auto\n",
    "from caiman.motion_correction import motion_correct_oneP_rigid\n",
    "import os\n",
    "import cv2\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except:\n",
    "    print('Open CV is naturally single threaded')\n",
    "import bokeh.plotting as bpl\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some parameters\n",
    "many of them will be set directly calling the CNMF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnames = ['data_endoscope.tif']\n",
    "frate = 10 # movie frame rate\n",
    "gSig = 3   # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "gSiz = 10  # average diameter of a neuron\n",
    "do_motion_correction = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset if not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded\n"
     ]
    }
   ],
   "source": [
    "base_folder = './example_movies/'  \n",
    "download_demo(fnames[0])\n",
    "fnames = [os.path.abspath(os.path.join(base_folder,fnames[0]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Re)start cluster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "10\n",
      "10\n",
      "0\n",
      "0\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "20\n",
      "20\n",
      "10\n",
      "20\n",
      "10\n",
      "20\n",
      "30\n",
      "20\n",
      "20\n",
      "20\n",
      "10\n",
      "10\n",
      "30\n",
      "30\n",
      "40\n",
      "30\n",
      "20\n",
      "30\n",
      "30\n",
      "20\n",
      "20\n",
      "30\n",
      "40\n",
      "40\n",
      "40\n",
      "50\n",
      "40\n",
      "30\n",
      "40\n",
      "30\n",
      "50\n",
      "30\n",
      "40\n",
      "50\n",
      "50\n",
      "50\n",
      "60\n",
      "60\n",
      "40\n",
      "40\n",
      "50\n",
      "40\n",
      "50\n",
      "70\n",
      "60\n",
      "60\n",
      "60\n",
      "50\n",
      "70\n",
      "50\n",
      "50\n",
      "80\n",
      "60\n",
      "60\n",
      "60\n",
      "90\n",
      "70\n",
      "70\n",
      "80\n",
      "60\n",
      "70\n",
      "60\n",
      "70\n",
      "70\n",
      "70\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "90\n",
      "90\n",
      "90\n",
      "0\n",
      "0\n",
      "0\n",
      "10\n",
      "0\n",
      "0\n",
      "0\n",
      "10\n",
      "20\n",
      "10\n",
      "0\n",
      "10\n",
      "10\n",
      "20\n",
      "30\n",
      "10\n",
      "20\n",
      "20\n",
      "40\n",
      "0\n",
      "0\n",
      "20\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "30\n",
      "30\n",
      "50\n",
      "10\n",
      "10\n",
      "40\n",
      "30\n",
      "30\n",
      "10\n",
      "20\n",
      "40\n",
      "40\n",
      "60\n",
      "20\n",
      "20\n",
      "50\n",
      "50\n",
      "30\n",
      "40\n",
      "20\n",
      "40\n",
      "70\n",
      "50\n",
      "30\n",
      "60\n",
      "30\n",
      "60\n",
      "40\n",
      "80\n",
      "30\n",
      "50\n",
      "50\n",
      "70\n",
      "60\n",
      "40\n",
      "40\n",
      "70\n",
      "90\n",
      "60\n",
      "50\n",
      "50\n",
      "40\n",
      "80\n",
      "60\n",
      "70\n",
      "50\n",
      "70\n",
      "80\n",
      "60\n",
      "60\n",
      "90\n",
      "50\n",
      "70\n",
      "80\n",
      "60\n",
      "80\n",
      "90\n",
      "70\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "70\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "90\n",
      "90\n",
      "90\n",
      "0\n",
      "0\n",
      "10\n",
      "0\n",
      "0\n",
      "20\n",
      "10\n",
      "10\n",
      "10\n",
      "0\n",
      "30\n",
      "0\n",
      "20\n",
      "0\n",
      "40\n",
      "20\n",
      "10\n",
      "20\n",
      "10\n",
      "0\n",
      "30\n",
      "50\n",
      "10\n",
      "20\n",
      "30\n",
      "20\n",
      "30\n",
      "0\n",
      "0\n",
      "10\n",
      "60\n",
      "40\n",
      "20\n",
      "30\n",
      "30\n",
      "40\n",
      "40\n",
      "10\n",
      "10\n",
      "30\n",
      "40\n",
      "40\n",
      "70\n",
      "20\n",
      "50\n",
      "20\n",
      "50\n",
      "50\n",
      "50\n",
      "20\n",
      "50\n",
      "40\n",
      "80\n",
      "30\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "30\n",
      "90\n",
      "50\n",
      "30\n",
      "60\n",
      "40\n",
      "70\n",
      "70\n",
      "70\n",
      "60\n",
      "40\n",
      "70\n",
      "40\n",
      "80\n",
      "70\n",
      "50\n",
      "80\n",
      "70\n",
      "80\n",
      "90\n",
      "50\n",
      "50\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "60\n",
      "90\n",
      "60\n",
      "90\n",
      "90\n",
      "70\n",
      "90\n",
      "70\n",
      "70\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "0\n",
      "0\n",
      "10\n",
      "0\n",
      "10\n",
      "0\n",
      "10\n",
      "0\n",
      "0\n",
      "20\n",
      "0\n",
      "20\n",
      "0\n",
      "10\n",
      "10\n",
      "20\n",
      "10\n",
      "30\n",
      "10\n",
      "30\n",
      "10\n",
      "20\n",
      "20\n",
      "20\n",
      "40\n",
      "30\n",
      "20\n",
      "30\n",
      "40\n",
      "20\n",
      "30\n",
      "30\n",
      "50\n",
      "40\n",
      "0\n",
      "40\n",
      "30\n",
      "50\n",
      "0\n",
      "30\n",
      "40\n",
      "40\n",
      "10\n",
      "60\n",
      "50\n",
      "40\n",
      "10\n",
      "40\n",
      "50\n",
      "50\n",
      "60\n",
      "50\n",
      "60\n",
      "20\n",
      "50\n",
      "20\n",
      "50\n",
      "60\n",
      "70\n",
      "60\n",
      "70\n",
      "70\n",
      "60\n",
      "30\n",
      "60\n",
      "60\n",
      "70\n",
      "30\n",
      "80\n",
      "80\n",
      "70\n",
      "40\n",
      "70\n",
      "80\n",
      "70\n",
      "70\n",
      "40\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "50\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "50\n",
      "60\n",
      "90\n",
      "90\n",
      "90\n",
      "90\n",
      "70\n",
      "60\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "90\n",
      "(1000, 81, 80)\n",
      "using 1 processes\n",
      "(1000, 80, 81)\n",
      "using 1600 pixels per process\n",
      "(1000, 80, 80)\n",
      "using 1 processes\n",
      "using 5000 block_size\n",
      "using 1600 pixels per process\n",
      "using 1 processes\n",
      "preprocessing ...\n",
      "using 1600 pixels per process\n",
      "using 5000 block_size\n",
      "using 5000 block_size\n",
      "checking if missing data\n",
      "(1000, 81, 81)\n",
      "preprocessing ...\n",
      "preprocessing ...\n",
      "using 1 processes\n",
      "checking if missing data\n",
      "checking if missing data\n",
      "using 1600 pixels per process\n",
      "using 5000 block_size\n",
      "preprocessing ...\n",
      "checking if missing data\n",
      "initializing ...\n",
      "Spatial Downsampling 1-photon\n",
      "initializing ...\n",
      "initializing ...\n",
      "Spatial Downsampling 1-photon\n",
      "Spatial Downsampling 1-photon\n",
      "Roi Extraction...\n",
      "One photon initialization..\n",
      "initializing ...\n",
      "Spatial Downsampling 1-photon\n",
      "Roi Extraction...\n",
      "One photon initialization..\n",
      "Roi Extraction...\n",
      "One photon initialization..\n",
      "Roi Extraction...\n",
      "One photon initialization..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 neurons have been initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 neurons have been initialized\n",
      "0 neurons have been initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 neurons have been initialized\n",
      "In total,  8 neurons were initialized.\n",
      "Compute Background\n",
      "In total,  10 neurons were initialized.\n",
      "Compute Background\n",
      "In total,  8 neurons were initialized.\n",
      "In total,  10 neurons were initialized.\n",
      "Compute Background\n",
      "Compute Background\n",
      "Compute Residuals\n",
      "Initialization again\n",
      "Compute Residuals\n",
      "Initialization again\n",
      "Compute Residuals\n",
      "Initialization again\n",
      "Compute Residuals\n",
      "Initialization again\n",
      "0 neurons have been initialized\n",
      "0 neurons have been initialized\n",
      "0 neurons have been initialized\n",
      "0 neurons have been initialized\n",
      "In total,  25 neurons were initialized.\n",
      "Update Temporal\n",
      "Generating residuals\n",
      "In total,  31 neurons were initialized.\n",
      "Update Temporal\n",
      "Generating residuals\n",
      "entering the deconvolution \n",
      "10 out of total 33 temporal components updated\n",
      "entering the deconvolution \n",
      "19 out of total 33 temporal components updated\n",
      "In total,  40 neurons were initialized.\n",
      "In total,  35 neurons were initialized.\n",
      "Update Temporal\n",
      "Update Temporal\n",
      "Generating residuals\n",
      "Generating residuals\n",
      "27 out of total 33 temporal components updated\n",
      "13 out of total 41 temporal components updated\n",
      "31 out of total 33 temporal components updated\n",
      "33 out of total 33 temporal components updated\n",
      "22 out of total 41 temporal components updated\n",
      "29 out of total 41 temporal components updated\n",
      "10 out of total 33 temporal components updated\n",
      "34 out of total 41 temporal components updated\n",
      "38 out of total 41 temporal components updated\n",
      "40 out of total 41 temporal components updated\n",
      "entering the deconvolution \n",
      "41 out of total 41 temporal components updated\n",
      "19 out of total 33 temporal components updated\n",
      "entering the deconvolution \n",
      "27 out of total 33 temporal components updated\n",
      "12 out of total 48 temporal components updated\n",
      "13 out of total 41 temporal components updated\n",
      "31 out of total 33 temporal components updated\n",
      "12 out of total 45 temporal components updated\n",
      "33 out of total 33 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "Update Spatial\n",
      "Initializing update of Spatial Components\n",
      "computing the distance indicators\n",
      "23 out of total 48 temporal components updated\n",
      "22 out of total 41 temporal components updated\n",
      "22 out of total 45 temporal components updated\n",
      "29 out of total 41 temporal components updated\n",
      "31 out of total 48 temporal components updated\n",
      "34 out of total 41 temporal components updated\n",
      "30 out of total 45 temporal components updated\n",
      "38 out of total 48 temporal components updated\n",
      "memmaping\n",
      "38 out of total 41 temporal components updated\n",
      "40 out of total 41 temporal components updated\n",
      "41 out of total 41 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "Update Spatial\n",
      "44 out of total 48 temporal components updated\n",
      "38 out of total 45 temporal components updated\n",
      "Initializing update of Spatial Components\n",
      "computing the distance indicators\n",
      "Updating Spatial Components using lasso lars\n",
      "47 out of total 48 temporal components updated\n",
      "48 out of total 48 temporal components updated\n",
      "43 out of total 45 temporal components updated\n",
      "45 out of total 45 temporal components updated\n",
      "memmaping\n",
      "Updating Spatial Components using lasso lars\n",
      "12 out of total 48 temporal components updated\n",
      "12 out of total 45 temporal components updated\n",
      "23 out of total 48 temporal components updated\n",
      "22 out of total 45 temporal components updated\n",
      "31 out of total 48 temporal components updated\n",
      "30 out of total 45 temporal components updated\n",
      "38 out of total 48 temporal components updated\n",
      "38 out of total 45 temporal components updated\n",
      "44 out of total 48 temporal components updated\n",
      "47 out of total 48 temporal components updated\n",
      "43 out of total 45 temporal components updated\n",
      "48 out of total 48 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "Update Spatial\n",
      "Initializing update of Spatial Components\n",
      "45 out of total 45 temporal components updated\n",
      "computing the distance indicators\n",
      "stopping: overall temporal component not changing significantly\n",
      "Update Spatial\n",
      "Initializing update of Spatial Components\n",
      "computing the distance indicators\n",
      "memmaping\n",
      "Updating Spatial Components using lasso lars\n",
      "memmaping\n",
      "Updating Spatial Components using lasso lars\n",
      "thresholding components\n",
      "Computing residuals\n",
      "--- 2.2565221786499023 seconds ---\n",
      "Removing tempfiles created\n",
      "Compute Background Again\n",
      "thresholding components\n",
      "Computing residuals\n",
      "--- 2.468146800994873 seconds ---\n",
      "Removing tempfiles created\n",
      "Compute Background Again\n",
      "thresholding components\n",
      "Update Temporal\n",
      "Computing residuals\n",
      "--- 2.803988456726074 seconds ---\n",
      "Removing tempfiles created\n",
      "Compute Background Again\n",
      "thresholding components\n",
      "Computing residuals\n",
      "--- 2.891413688659668 seconds ---\n",
      "Removing tempfiles created\n",
      "Compute Background Again\n",
      "Generating residuals\n",
      "entering the deconvolution \n",
      "Update Temporal\n",
      "11 out of total 33 temporal components updated\n",
      "18 out of total 33 temporal components updated\n",
      "26 out of total 33 temporal components updated\n",
      "30 out of total 33 temporal components updated\n",
      "32 out of total 33 temporal components updated\n",
      "33 out of total 33 temporal components updated\n",
      "11 out of total 33 temporal components updated\n",
      "Generating residuals\n",
      "18 out of total 33 temporal components updated\n",
      "26 out of total 33 temporal components updated\n",
      "30 out of total 33 temporal components updated\n",
      "32 out of total 33 temporal components updated\n",
      "33 out of total 33 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "Update Spatial\n",
      "Initializing update of Spatial Components\n",
      "computing the distance indicators\n",
      "memmaping\n",
      "Updating Spatial Components using lasso lars\n",
      "entering the deconvolution \n",
      "10 out of total 41 temporal components updated\n",
      "19 out of total 41 temporal components updated\n",
      "27 out of total 41 temporal components updated\n",
      "Update Temporal\n",
      "33 out of total 41 temporal components updated\n",
      "37 out of total 41 temporal components updated\n",
      "40 out of total 41 temporal components updated\n",
      "41 out of total 41 temporal components updated\n",
      "Update Temporal\n",
      "10 out of total 41 temporal components updated\n",
      "19 out of total 41 temporal components updated\n",
      "Generating residuals\n",
      "27 out of total 41 temporal components updated\n",
      "33 out of total 41 temporal components updated\n",
      "Generating residuals\n",
      "37 out of total 41 temporal components updated\n",
      "40 out of total 41 temporal components updated\n",
      "41 out of total 41 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "Update Spatial\n",
      "Initializing update of Spatial Components\n",
      "computing the distance indicators\n",
      "entering the deconvolution \n",
      "11 out of total 45 temporal components updated\n",
      "22 out of total 45 temporal components updated\n",
      "memmaping\n",
      "Updating Spatial Components using lasso lars\n",
      "entering the deconvolution \n",
      "32 out of total 45 temporal components updated\n",
      "38 out of total 45 temporal components updated\n",
      "12 out of total 48 temporal components updated\n",
      "43 out of total 45 temporal components updated\n",
      "44 out of total 45 temporal components updated\n",
      "45 out of total 45 temporal components updated\n",
      "25 out of total 48 temporal components updated\n",
      "11 out of total 45 temporal components updated\n",
      "33 out of total 48 temporal components updated\n",
      "22 out of total 45 temporal components updated\n",
      "41 out of total 48 temporal components updated\n",
      "32 out of total 45 temporal components updated\n",
      "45 out of total 48 temporal components updated\n",
      "48 out of total 48 temporal components updated\n",
      "38 out of total 45 temporal components updated\n",
      "43 out of total 45 temporal components updated\n",
      "44 out of total 45 temporal components updated\n",
      "45 out of total 45 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "12 out of total 48 temporal components updated\n",
      "Update Spatial\n",
      "Initializing update of Spatial Components\n",
      "computing the distance indicators\n",
      "25 out of total 48 temporal components updated\n",
      "33 out of total 48 temporal components updated\n",
      "memmaping\n",
      "41 out of total 48 temporal components updated\n",
      "Updating Spatial Components using lasso lars\n",
      "45 out of total 48 temporal components updated\n",
      "48 out of total 48 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "Update Spatial\n",
      "Initializing update of Spatial Components\n",
      "computing the distance indicators\n",
      "memmaping\n",
      "Updating Spatial Components using lasso lars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholding components\n",
      "Computing residuals\n",
      "--- 5.255146503448486 seconds ---\n",
      "Removing tempfiles created\n",
      "Compute Background Again\n",
      "Estimate low rank Background\n",
      "thresholding components\n",
      "Computing residuals\n",
      "--- 6.151336908340454 seconds ---\n",
      "Removing tempfiles created\n",
      "Compute Background Again\n",
      "Estimate low rank Background\n",
      "thresholding components\n",
      "Computing residuals\n",
      "--- 6.6429455280303955 seconds ---\n",
      "Removing tempfiles created\n",
      "Compute Background Again\n",
      "thresholding components\n",
      "Computing residuals\n",
      "--- 7.067281246185303 seconds ---\n",
      "Removing tempfiles created\n",
      "Compute Background Again\n",
      "Estimate low rank Background\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/initialization.py:1100: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  f_in = np.linalg.lstsq(b_in, B)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel dot product block size: 1000\n",
      "Start product\n",
      "Transposing\n",
      "999\n",
      "1999\n",
      "2999\n",
      "3999\n",
      "4999\n",
      "5999\n",
      "6560\n",
      "Estimate low rank Background\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/initialization.py:1100: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  f_in = np.linalg.lstsq(b_in, B)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel dot product block size: 1000\n",
      "Start product\n",
      "Transposing\n",
      "999\n",
      "1999\n",
      "2999\n",
      "3999\n",
      "4999\n",
      "5999\n",
      "6479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/initialization.py:1100: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  f_in = np.linalg.lstsq(b_in, B)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel dot product block size: 1000\n",
      "Start product\n",
      "Transposing\n",
      "999\n",
      "1999\n",
      "2999\n",
      "3999\n",
      "4999\n",
      "5999\n",
      "6479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/initialization.py:1100: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  f_in = np.linalg.lstsq(b_in, B)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel dot product block size: 1000\n",
      "Start product\n",
      "Transposing\n",
      "999\n",
      "1999\n",
      "2999\n",
      "3999\n",
      "4999\n",
      "5999\n",
      "6399\n",
      "4999\n",
      "9999\n",
      "14999\n",
      "16383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n",
      "9999\n",
      "16383\n",
      "14999\n",
      "4999\n",
      "9999\n",
      "14999\n",
      "16383\n",
      "tB:-2.0,tA:9.0\n",
      "Computing event exceptionality delta\n",
      "tB:-2.0,tA:9.0\n",
      "Computing event exceptionality delta\n",
      "tB:-2.0,tA:9.0\n",
      "Computing event exceptionality delta\n",
      "Removing Baseline\n",
      "binning data ...\n",
      "interpolating data ...\n",
      "(5, 5)\n",
      "Computing event exceptionality\n",
      "Evaluating spatial footprint\n",
      "Removing Baseline\n",
      "binning data ...\n",
      "Removing Baseline\n",
      "interpolating data ...\n",
      "binning data ...\n",
      "(5, 50)\n",
      "interpolating data ...\n",
      "(5, 50)\n",
      "Computing event exceptionality\n",
      "components evaluated:0\n",
      "Computing event exceptionality\n",
      "Evaluating spatial footprint\n",
      "Evaluating spatial footprint\n",
      "components evaluated:0\n",
      "Neuron:0 includes overlaping spiking neurons\n",
      "Neuron:3 includes overlaping spiking neurons\n",
      "components evaluated:0\n",
      "Neuron:3 includes overlaping spiking neurons\n",
      "Neuron:5 includes overlaping spiking neurons\n",
      "Neuron:26 includes overlaping spiking neurons\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dview.terminate() # stop it if it was running\n",
    "except:\n",
    "    pass\n",
    "\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', # use this one\n",
    "                                                 n_processes=16,  # number of process to use, if you go out of memory try to reduce this one\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a memory mappable file. \n",
    "    - Performs motion correction and simultaneously creates a memory mappable file in F order\n",
    "    - Transforms into C order (much more efficient for parallel processing\n",
    "    - If you have multiple files there are ways to process many at the same time (not shown)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rigid Motion Correction\n",
      "5.3534045\n",
      "-1.699735164642334\n",
      "Frame 100\n",
      "cubic interpolation\n",
      "Frame 100\n",
      "-1.699735164642334\n",
      "Frame 100\n",
      "cubic interpolation\n",
      "Frame 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/base/movies.py:260: UserWarning: ** Pixels averages are too negative. Removing 1 percentile. **\n",
      "  '** Pixels averages are too negative. Removing 1 percentile. **')\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/base/movies.py:279: UserWarning: Pixels averages are too negative for template. Removing 1 percentile.\n",
      "  'Pixels averages are too negative for template. Removing 1 percentile.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.699735164642334\n",
      "Frame 100\n",
      "cubic interpolation\n",
      "Frame 100\n",
      "Adding to movie 5.3534045\n",
      "0\n",
      "saving!\n",
      "** Startting parallel motion correction **\n",
      "** Finished parallel motion correction **\n",
      "0.045475096\n",
      "/home/fpbatta/src/extern/CaImAn_stable/example_movies/data_endoscope_rig__d1_128_d2_128_d3_1_order_F_frames_1000_.mmap\n",
      "<class 'str'>\n",
      "/home/fpbatta/src/extern/CaImAn_stable/example_movies/data_endoscope_rig__d1_128_d2_128_d3_1_order_F_frames_1000_.mmap\n",
      "loading in memory\n",
      "mmap\n"
     ]
    }
   ],
   "source": [
    "if do_motion_correction:\n",
    "    mc = motion_correct_oneP_rigid(fnames[0],                        # name of file to motion correct\n",
    "                               gSig_filt = [gSig]*2,                 # size of filter, xhange this one if algorithm does not work \n",
    "                               max_shifts = [5,5],                   # maximum shifts allowed in each direction \n",
    "                               dview=dview, \n",
    "                               splits_rig = 10,                      # number of chunks for parallelizing motion correction (remember that it should hold that length_movie/num_splits_to_process_rig>100) \n",
    "                               save_movie = True)                    # whether to save movie in memory mapped format\n",
    "    \n",
    "    new_templ = mc.total_template_rig\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.subplot(1,2,1)    \n",
    "    plt.title('Filtered template')\n",
    "    plt.imshow(new_templ)       #% plot template\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Estimated shifts')\n",
    "    plt.plot(mc.shifts_rig)     #% plot rigid shifts\n",
    "    plt.legend(['x shifts', 'y shifts'])\n",
    "    plt.xlabel('frames')\n",
    "    plt.ylabel('pixels')\n",
    "    \n",
    "    bord_px_rig = np.ceil(np.max(mc.shifts_rig)).astype(np.int)     #borders to eliminate from movie because of motion correction        \n",
    "    fname_new = cm.save_memmap(mc.fname_tot_rig, base_name='memmap_', order = 'C') # transforming memoruy mapped file in C order (efficient to perform computing)\n",
    "else:\n",
    "    #% create memory mappable file\n",
    "    fname_new = cm.save_memmap(fnames, base_name='memmap_', order = 'C')\n",
    "\n",
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "Y = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the movie (optional). This will require loading the movie in memory which in general is not needed by the pipeline. Displaying the movie uses the OpenCV library. Press `q` to close the video panel. **BEWARE** the movie may appear in the background!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_orig = cm.movie(Y)\n",
    "downsample_ratio = 1.\n",
    "offset_mov = -np.min(m_orig[:100])  # make the dataset mostly non-negative\n",
    "m_orig.resize(1, 1, downsample_ratio).play(\n",
    "gain=2, offset=offset_mov, fr=30, magnification=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect summary images and set parameters\n",
    "Check the optimal values of min_corr and min_pnr by moving slider in the figure that pops up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute some summary images (correlation and peak to noise)\n",
    "cn_filter, pnr = cm.summary_images.correlation_pnr(Y, gSig=gSig, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "# inspect the summary images and set the parameters\n",
    "inspect_correlation_pnr(cn_filter,pnr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_corr = .8 # min correlation of peak (from correlation image)\n",
    "min_pnr = 10 # min peak to noise ratio\n",
    "min_SNR = 3 # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.85  # threshold on space consistency (if you lower more components will be accepted, potentially with worst quality)\n",
    "decay_time = 0.4  #decay time of transients/indocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set CNMF parameters and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 128, 128)\n",
      "using 16 processes\n",
      "using 4000 pixels per process\n",
      "using 5000 block_size\n",
      "(80, 80)\n",
      "17.184683799743652\n",
      "Transforming patches into full matrix\n",
      "Skipped %d Empty Patch 0\n",
      "Generating background\n",
      "Compressing background components with a low rank NMF\n",
      "Generating background DONE\n",
      "merging\n",
      "[30 31]\n",
      "[81 98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/anaconda3/envs/caiman/lib/python3.6/site-packages/scipy/sparse/compressed.py:742: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n",
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/source_extraction/cnmf/deconvolution.py:1019: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  g = np.linalg.lstsq(A, xc[lags + 1:])[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No neurons merged!\n",
      "update temporal\n",
      "Generating residuals\n",
      "parallel dot product block size: 5000\n",
      "Start product\n",
      "Processed:[0, 4]\n",
      "Transposing\n",
      "entering the deconvolution \n",
      "28 out of total 105 temporal components updated\n",
      "51 out of total 105 temporal components updated\n",
      "67 out of total 105 temporal components updated\n",
      "82 out of total 105 temporal components updated\n",
      "95 out of total 105 temporal components updated\n",
      "103 out of total 105 temporal components updated\n",
      "105 out of total 105 temporal components updated\n",
      "28 out of total 105 temporal components updated\n",
      "51 out of total 105 temporal components updated\n",
      "67 out of total 105 temporal components updated\n",
      "82 out of total 105 temporal components updated\n",
      "95 out of total 105 temporal components updated\n",
      "103 out of total 105 temporal components updated\n",
      "105 out of total 105 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "update spatial ...\n",
      "Initializing update of Spatial Components\n",
      "computing the distance indicators\n",
      "memmaping\n",
      "Updating Spatial Components using lasso lars\n",
      "thresholding components\n",
      "Computing residuals\n",
      "parallel dot product block size: 5000\n",
      "Start product\n",
      "Processed:[0, 4]\n",
      "Filling\n",
      "--- 10.734652042388916 seconds ---\n",
      "Removing tempfiles created\n",
      "update temporal\n",
      "Generating residuals\n",
      "parallel dot product block size: 5000\n",
      "Start product\n",
      "Processed:[0, 4]\n",
      "Transposing\n",
      "entering the deconvolution \n",
      "27 out of total 105 temporal components updated\n",
      "48 out of total 105 temporal components updated\n",
      "66 out of total 105 temporal components updated\n",
      "81 out of total 105 temporal components updated\n",
      "95 out of total 105 temporal components updated\n",
      "104 out of total 105 temporal components updated\n",
      "105 out of total 105 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<caiman.source_extraction.cnmf.cnmf.CNMF at 0x7f2a603be278>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnm = cnmf.CNMF(n_processes=n_processes, \n",
    "                method_init='corr_pnr',                 # use this for 1 photon\n",
    "                k=70,                                   # neurons per patch\n",
    "                gSig=(3, 3),                            # half size of neuron\n",
    "                gSiz=(10, 10),                          # in general 3*gSig+1\n",
    "                merge_thresh=.8,                        # threshold for merging\n",
    "                p=1,                                    # order of autoregressive process to fit\n",
    "                dview=dview,                            # if None it will run on a single thread\n",
    "                tsub=2,                                 # downsampling factor in time for initialization, increase if you have memory problems             \n",
    "                ssub=2,                                 # downsampling factor in space for initialization, increase if you have memory problems\n",
    "                Ain=None,                               # if you want to initialize with some preselcted components you can pass them here as boolean vectors\n",
    "                rf=(40, 40),                            # half size of the patch (final patch will be 100x100)\n",
    "                stride=(20, 20),                        # overlap among patches (keep it at least large as 4 times the neuron size)\n",
    "                only_init_patch=True,                   # just leave it as is\n",
    "                gnb=16,                                 # number of background components\n",
    "                nb_patch=16,                            # number of background components per patch\n",
    "                method_deconvolution='oasis',           #could use 'cvxpy' alternatively\n",
    "                low_rank_background=True,               #leave as is\n",
    "                update_background_components=True,      # sometimes setting to False improve the results\n",
    "                min_corr=min_corr,                      # min peak value from correlation image \n",
    "                min_pnr=min_pnr,                        # min peak to noise ration from PNR image\n",
    "                normalize_init=False,                   # just leave as is\n",
    "                center_psf=True,                        # leave as is for 1 photon\n",
    "                del_duplicates=True)                    # whether to remove duplicates from initialization\n",
    "\n",
    "cnm.fit(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot contours of identified components against correlation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/utils/visualization.py:941: UserWarning: The way to call utilities.plot_contours has changed. Look at the definition for more details.\n",
      "  warn(\"The way to call utilities.plot_contours has changed. Look at the definition for more details.\")\n"
     ]
    }
   ],
   "source": [
    "crd = cm.utils.visualization.plot_contours(cnm.A, cn_filter, thr=.8, vmax=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier\n",
    "\n",
    "<img src=\"docs/img/evaluationcomponent.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING IN PARALLEL... NOT RETURNING ERFCs\n",
      " ***** \n",
      "105\n",
      "91\n",
      "[ 0.44978039 -0.22632325  0.03454946  0.36198095  0.06155593 -0.01481715\n",
      "  0.39492054 -0.05129989  0.11592654  0.40387176  0.39647351 -0.27337794\n",
      "  0.20040096 -0.49295236]\n"
     ]
    }
   ],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "idx_components, idx_components_bad, comp_SNR, r_values, pred_CNN = estimate_components_quality_auto(\n",
    "                            Y, cnm.A, cnm.C, cnm.b, cnm.f, cnm.YrA, frate, \n",
    "                            decay_time, gSig, dims, dview = dview, \n",
    "                            min_SNR=min_SNR, r_values_min = r_values_min, min_std_reject = 0.5, use_cnn = False)\n",
    "\n",
    "print(' ***** ')\n",
    "print((len(cnm.C)))\n",
    "print((len(idx_components)))\n",
    "print(r_values[idx_components_bad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpbatta/src/extern/CaImAn_stable/caiman/utils/visualization.py:941: UserWarning: The way to call utilities.plot_contours has changed. Look at the definition for more details.\n",
      "  warn(\"The way to call utilities.plot_contours has changed. Look at the definition for more details.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Contour plots of rejected components')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "\n",
    "plt.figure(figsize=(15,8));\n",
    "plt.subplot(121);\n",
    "crd = cm.utils.visualization.plot_contours(cnm.A.tocsc()[:,idx_components], cn_filter, thr=.8, vmax=0.95)\n",
    "plt.title('Contour plots of accepted components')\n",
    "plt.subplot(122); \n",
    "crd = cm.utils.visualization.plot_contours(cnm.A.tocsc()[:,idx_components_bad], cn_filter, thr=.8, vmax=0.95)\n",
    "plt.title('Contour plots of rejected components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"619f44a5-81dc-434d-9137-f0ac59e99c88\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {},
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "3e8b994f-f2e9-41fc-b4ee-6efd6d382da0"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accepted components\n",
    "nb_view_patches(Yr, cnm.A.tocsc()[:, idx_components], cnm.C[idx_components], \n",
    "                cnm.b, cnm.f, dims[0], dims[1], YrA=cnm.YrA[idx_components], image_neurons = cn_filter,\n",
    "                denoised_color = 'red', thr=0.8, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"97cd5d81-3dff-4962-9f78-bbb6d58e092f\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {},
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "42b02248-a5ee-4211-98b7-224b8a771c1b"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rejected components\n",
    "nb_view_patches(Yr, cnm.A.tocsc()[:, idx_components_bad], cnm.C[idx_components_bad], \n",
    "                cnm.b, cnm.f, dims[0], dims[1], YrA=cnm.YrA[idx_components_bad], image_neurons = cn_filter,\n",
    "                denoised_color = 'red', thr=0.8, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "cm.stop_server(dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some instructive movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% denoised movie\n",
    "cm.movie(np.reshape(cnm.A.tocsc()[:,idx_components].dot(cnm.C[idx_components])+cnm.b.dot(cnm.f),dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% only neurons\n",
    "cm.movie(np.reshape(cnm.A.tocsc()[:,idx_components].dot(cnm.C[idx_components]),dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% only the background\n",
    "cm.movie(np.reshape(cnm.b.dot(cnm.f),dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% residuals\n",
    "cm.movie(np.array(Y)-np.reshape(cnm.A.tocsc()[:,:].dot(cnm.C[:])+cnm.b.dot(cnm.f),dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 10., fr = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2a4bb982e8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% eventuall, you can rerun the algorithm on the residuals\n",
    "plt.imshow(cm.movie(np.array(Y)-np.reshape(cnm.A.tocsc()[:,:].dot(cnm.C[:])+cnm.b.dot(cnm.f),dims+(-1,), order = 'F').transpose(2,0,1)).local_correlations(swap_dim=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
